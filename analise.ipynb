{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Experimental Definitiva de Meta-heurísticas: da Visão Geral ao Comportamento Detalhado\n",
    "\n",
    "Este notebook apresenta uma análise completa e multi-nível do desempenho de quatro algoritmos de otimização. A análise progride desde uma visão estatística agregada até um mergulho profundo na trajetória de busca de uma única execução, oferecendo insights sobre a eficácia e o comportamento de cada método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Configuração visual dos gráficos\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"viridis\")\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (15, 9),\n",
    "    'figure.dpi': 110,\n",
    "    'axes.titlesize': 18,\n",
    "    'axes.labelsize': 14,\n",
    "    'legend.fontsize': 12,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12\n",
    "})\n",
    "print(\"Bibliotecas importadas e configurações de plotagem aplicadas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Carregamento e Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_data(base_path, max_time=2.0):\n",
    "    \"\"\"Carrega e limpa os dados de resultado final.\"\"\"\n",
    "    search_pattern = os.path.join(base_path, \"run_*\", \"*\", \"*\", \"saida_*.txt\")\n",
    "    file_paths = glob.glob(search_pattern)\n",
    "    if not file_paths: return pd.DataFrame()\n",
    "    all_data = []\n",
    "    abs_base_path = os.path.abspath(base_path)\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            relative_path = os.path.relpath(file_path, abs_base_path)\n",
    "            parts = relative_path.split(os.sep)\n",
    "            if len(parts) != 4: continue\n",
    "            df_temp = pd.read_csv(file_path, sep=' ', header=None, names=['valor', 'tempo'])\n",
    "            df_temp['run'] = int(parts[0].replace(\"run_\", \"\"))\n",
    "            df_temp['algoritmo'] = parts[1]\n",
    "            df_temp['tipo_instancia'] = parts[2]\n",
    "            df_temp['tamanho_instancia'] = int(parts[3].replace(\"saida_\", \"\").replace(\".txt\", \"\"))\n",
    "            all_data.append(df_temp)\n",
    "        except: pass\n",
    "    df_raw = pd.concat(all_data, ignore_index=True)\n",
    "    df_cleaned = df_raw[(df_raw['valor'] >= 0) & (df_raw['tempo'] <= max_time)].copy()\n",
    "    return df_cleaned\n",
    "\n",
    "def load_trajectory_data(base_path):\n",
    "    \"\"\"Carrega os dados de trajetória/convergência por iteração.\"\"\"\n",
    "    search_pattern = os.path.join(base_path, \"run_*\", \"*\", \"*\", \"conv_*.txt\")\n",
    "    file_paths = glob.glob(search_pattern)\n",
    "    if not file_paths: return pd.DataFrame()\n",
    "\n",
    "    all_data = []\n",
    "    abs_base_path = os.path.abspath(base_path)\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            relative_path = os.path.relpath(file_path, abs_base_path)\n",
    "            parts = relative_path.split(os.sep)\n",
    "            if len(parts) != 4: continue\n",
    "            df_temp = pd.read_csv(file_path, sep=' ', header=None, names=['iteracao', 'valor'])\n",
    "            df_temp['run'] = int(parts[0].replace(\"run_\", \"\"))\n",
    "            df_temp['algoritmo'] = parts[1]\n",
    "            df_temp['tipo_instancia'] = parts[2]\n",
    "            fname_parts = parts[3].replace(\".txt\", \"\").split('_')\n",
    "            df_temp['cenario'] = int(fname_parts[1].replace('s', ''))\n",
    "            df_temp['tamanho_instancia'] = int(fname_parts[3].replace('z', ''))\n",
    "            all_data.append(df_temp)\n",
    "        except: pass\n",
    "    return pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()\n",
    "\n",
    "# Carregando os dados\n",
    "results_path = '/home/mjf30/otmgraf/Otimizacao-Grafos/resultados'\n",
    "convergence_path = '/home/mjf30/otmgraf/Otimizacao-Grafos/convergencia'\n",
    "\n",
    "df_results = load_and_clean_data(results_path)\n",
    "df_trajectory = load_trajectory_data(convergence_path)\n",
    "\n",
    "if not df_results.empty: print(f\"Dados de resultados finais carregados: {len(df_results)} registros.\")\n",
    "if not df_trajectory.empty: print(f\"Dados de trajetória carregados: {len(df_trajectory)} registros.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Análise Agregada e Visualizações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_results.empty:\n",
    "    summary_stats = df_results.groupby(['algoritmo', 'tipo_instancia', 'tamanho_instancia']).agg(\n",
    "        valor_medio=('valor', 'mean'),\n",
    "        valor_std=('valor', 'std'),\n",
    "        tempo_medio=('tempo', 'mean'),\n",
    "        tempo_std=('tempo', 'std')\n",
    "    ).reset_index()\n",
    "    summary_stats['cv_valor_%'] = (summary_stats['valor_std'] / (summary_stats['valor_medio'].abs() + 1e-9)) * 100\n",
    "    summary_stats['cv_tempo_%'] = (summary_stats['tempo_std'] / (summary_stats['tempo_medio'].abs() + 1e-9)) * 100\n",
    "    \n",
    "    # Boxplots para consistência\n",
    "    instance_types_in_data = sorted(df_results['tipo_instancia'].unique())\n",
    "    for inst_type in instance_types_in_data:\n",
    "        print(f\"\\n{'='*25} ANÁLISE VISUAL PARA: {inst_type.upper()} {'='*25}\")\n",
    "        plt.figure()\n",
    "        sns.boxplot(data=df_results[df_results['tipo_instancia'] == inst_type], x='tamanho_instancia', y='valor', hue='algoritmo')\n",
    "        plt.title(f'Consistência dos Resultados - {inst_type}', weight='bold')\n",
    "        plt.ylabel('Valor da Solução (Fitness)'); plt.xlabel('Tamanho da Instância')\n",
    "        plt.legend(title='Algoritmo', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "        plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Análise de Trajetória de Busca (Execução Única)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_trajectory.empty:\n",
    "    target_type = 'fully_correlated_sc'\n",
    "    target_size = 1000\n",
    "    target_run = 1\n",
    "\n",
    "    data_traj = df_trajectory[\n",
    "        (df_trajectory['tipo_instancia'] == target_type) &\n",
    "        (df_trajectory['tamanho_instancia'] == target_size) &\n",
    "        (df_trajectory['run'] == target_run)\n",
    "    ]\n",
    "\n",
    "    if not data_traj.empty:\n",
    "        plt.figure()\n",
    "        sns.lineplot(data=data_traj, x='iteracao', y='valor', hue='algoritmo', \n",
    "                     style='algoritmo', markers=False, drawstyle='steps-post', linewidth=2.5)\n",
    "        \n",
    "        plt.title(f'Trajetória de Busca por Iteração (Execução Única)\\n{target_type} - {target_size} - Run {target_run}', weight='bold')\n",
    "        plt.xlabel('Número de Iterações')\n",
    "        plt.ylabel('Valor da Melhor Solução Encontrada')\n",
    "        plt.legend(title='Algoritmo')\n",
    "        plt.grid(True, which='both', linestyle='--')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Nenhum dado de trajetória encontrado para {target_type}, {target_size}, Run {target_run}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Análise de Trade-Off e Significância Estatística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_pareto(scores):\n",
    "    population_size = scores.shape[0]\n",
    "    pareto_front = np.ones(population_size, dtype=bool)\n",
    "    for i in range(population_size):\n",
    "        for j in range(population_size):\n",
    "            if all(scores[j] >= scores[i]) and any(scores[j] > scores[i]):\n",
    "                pareto_front[i] = False\n",
    "                break\n",
    "    return pareto_front\n",
    "\n",
    "if not df_results.empty:\n",
    "    instances_to_analyze = [\n",
    "        ('correlated_sc', 500),\n",
    "        ('fully_correlated_sc', 1000),\n",
    "        ('not_correlated_sc', 800)\n",
    "    ]\n",
    "\n",
    "    # Gráficos de Pareto\n",
    "    for inst_type, inst_size in instances_to_analyze:\n",
    "        data_pareto = df_results[(df_results['tipo_instancia'] == inst_type) & (df_results['tamanho_instancia'] == inst_size)]\n",
    "        if data_pareto.empty: continue\n",
    "        plt.figure()\n",
    "        sns.scatterplot(data=data_pareto, x='tempo', y='valor', hue='algoritmo', alpha=0.5, s=60, style='algoritmo')\n",
    "        scores = np.array([data_pareto['valor'], -data_pareto['tempo']]).T\n",
    "        global_pareto_mask = identify_pareto(scores)\n",
    "        global_pareto_points = data_pareto[global_pareto_mask]\n",
    "        plt.scatter(global_pareto_points['tempo'], global_pareto_points['valor'], s=250, facecolors='none', edgecolors='red', marker='o', linewidth=2.5, label='Fronteira Pareto Global', zorder=10)\n",
    "        plt.title(f'Fronteira de Pareto: Qualidade vs. Tempo\\n{inst_type} - {inst_size}', weight='bold')\n",
    "        plt.xlabel('Tempo de Execução (s)'); plt.ylabel('Valor da Solução (Fitness)')\n",
    "        plt.legend(title='Algoritmo / Destaque', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "        plt.grid(True, which='both', linestyle='--')\n",
    "        plt.tight_layout(); plt.show()\n",
    "\n",
    "    # Testes Estatísticos\n",
    "    for inst_type, inst_size in instances_to_analyze:\n",
    "        print(f\"\\n{'='*20} Análise Estatística para: {inst_type.upper()}, Tamanho: {inst_size} {'='*20}\")\n",
    "        data_for_test = df_results[(df_results['tipo_instancia'] == inst_type) & (df_results['tamanho_instancia'] == inst_size)]\n",
    "        if len(data_for_test['algoritmo'].unique()) < 2: continue\n",
    "        samples = [group['valor'].values for name, group in data_for_test.groupby('algoritmo')]\n",
    "        f_statistic, p_value_anova = stats.f_oneway(*samples)\n",
    "        print(f\"--- Teste ANOVA --- -> P-valor: {p_value_anova:.4g}\")\n",
    "        if p_value_anova < 0.05:\n",
    "            print(\"-> Conclusão ANOVA: Existe uma diferença estatisticamente significante.\")\n",
    "            tukey_results = pairwise_tukeyhsd(endog=data_for_test['valor'], groups=data_for_test['algoritmo'], alpha=0.05)\n",
    "            print(\"--- Teste Post-Hoc de Tukey HSD ---\")\n",
    "            print(tukey_results)\n",
    "        else:\n",
    "            print(\"-> Conclusão ANOVA: NÃO há evidência de diferença estatisticamente significante.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Tabelas de Resumo para Relatório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'summary_stats' in locals() and not summary_stats.empty:\n",
    "    # --- Tabela Resumo (Formato Texto Simples) ---\n",
    "    target_size_report = 1000\n",
    "    data_report = summary_stats[summary_stats['tamanho_instancia'] == target_size_report]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"### RELATÓRIO CONSOLIDADO PARA INSTÂNCIAS DE TAMANHO N = {target_size_report} ###\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    for inst_type in sorted(data_report['tipo_instancia'].unique()):\n",
    "        print(f\"--- TIPO DE INSTÂNCIA: {inst_type.upper()} ---\\n\")\n",
    "        subset = data_report[data_report['tipo_instancia'] == inst_type].sort_values(by='valor_medio', ascending=False)\n",
    "        \n",
    "        for _, row in subset.iterrows():\n",
    "            print(f\"** {row['algoritmo'].upper()} **\")\n",
    "            print(f\"    - Média das soluções: {row['valor_medio']:.0f}\")\n",
    "            print(f\"    - Coeficiente de Variação (Soluções): {row['cv_valor_%']:.2f}%\")\n",
    "            print(f\"    - Média dos Tempos: {row['tempo_medio']:.3f} seg\")\n",
    "            print(f\"    - Coeficiente de Variação (Tempo): {row['cv_tempo_%']:.1f}%\\n\")\n",
    "        print(\"---\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}